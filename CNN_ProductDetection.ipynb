{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Product Detection using CNN & Transfer Learning\n",
    "-----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "This notebook will be looking at Transfer Learning architectures in the context of product detection for e-commerce sites. I will be exploring a variety of pre-trained architecures, and experimenting with variants of the model including model augmentation, model fine-tuning, as well as the effects of varying the extent of weight retraining.\n",
    "\n",
    "In the models below, you will find the following key **variations**:\n",
    "- ```Augmentation```:\n",
    "    - This indicates that the model utilizes image augmentation using ```ImageDataGenerator``` to rotate, flip , resize images for more robust out-of-sample performance / regularization\n",
    "- ```Fine Tune```:\n",
    "    - This indicates that the model unfreezes specific layer blocks for retraining \n",
    "- ```Revamp```\n",
    "    - This indicates that the model unfreezes all layers for retraining while retaining the pre-trained architecture\n",
    "    \n",
    "### Results\n",
    "\n",
    "- In the final section, I present the product detection based on a test set with no labels. The results can be seen in the ```test_results``` folder, which contains aggregate images according to the model's predicted class. On a whole, the model seems to perform relatively well for a simple training purposes. As expected, classification for some classes perform significantly better than for other classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import random\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "\n",
    "from keras.models import Model\n",
    "from keras.models import Sequential\n",
    "from keras.models import save_model\n",
    "from keras.models import load_model\n",
    "from keras import optimizers\n",
    "from keras.optimizers import RMSprop\n",
    "from keras.optimizers import Adam\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.preprocessing.image import load_img\n",
    "from keras.preprocessing.image import img_to_array\n",
    "from keras.preprocessing.image import array_to_img\n",
    "from keras.layers import InputLayer\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Dropout\n",
    "from keras.layers import GlobalAveragePooling2D\n",
    "\n",
    "from utils import update_progress"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Data Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.1 Importing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "train_labels = list()\n",
    "train_imgs = list()\n",
    "\n",
    "bad_imgs = list()\n",
    "\n",
    "train_root = 'data/train/train/'\n",
    "\n",
    "ii = 0\n",
    "finish = 42\n",
    "\n",
    "\n",
    "for cat in os.listdir(train_root):\n",
    "    \n",
    "    if cat != '.DS_Store':\n",
    "        \n",
    "        for jpg in os.listdir(train_root + cat):\n",
    "\n",
    "            path = train_root + cat + '/' + jpg\n",
    "\n",
    "            try:\n",
    "\n",
    "                train_imgs.append(img_to_array(load_img(\n",
    "                        path, target_size=IMG_DIM)))       \n",
    "                train_labels.append(str(int(cat)))\n",
    "\n",
    "            except:\n",
    "\n",
    "                bad_imgs.append(path)\n",
    "    \n",
    "    ii += 1\n",
    "    update_progress(ii/finish)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.2 Scaling Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_imgs = np.array(train_imgs)\n",
    "train_imgs_scaled = train_imgs.astype('float32')\n",
    "train_imgs_scaled /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.3 One-Hot Encode Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_labels = [int(i) for i in train_labels]\n",
    "\n",
    "enc = OneHotEncoder()\n",
    "enc.fit(np.array(train_labels).reshape(-1, 1))\n",
    "\n",
    "train_labels_enc = \\\n",
    "    enc.transform(np.array(train_labels).reshape(-1, 1)).toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.4 Train-Val split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_prop = 0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_index = random.sample(range(1, len(train_imgs_scaled)), round(val_prop * len(train_imgs_scaled)))\n",
    "train_index = [ii for ii in range(len(train_imgs_scaled)) if ii not in val_index]\n",
    "random.shuffle(train_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs_scaled = train_imgs_scaled[val_index]\n",
    "train_imgs_scaled = train_imgs_scaled[train_index]\n",
    "val_labels_enc = train_labels_enc[val_index] \n",
    "train_labels_enc = train_labels_enc[train_index]\n",
    "\n",
    "print(val_imgs_scaled.shape)\n",
    "print(train_imgs_scaled.shape)\n",
    "print(val_labels_enc.shape)\n",
    "print(train_labels_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.5 Saving Tensors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_data/train_imgs_scaled.npy', train_imgs_scaled)\n",
    "np.save('model_data/val_imgs_scaled.npy', val_imgs_scaled)\n",
    "np.save('model_data/train_labels_enc.npy', train_labels_enc)\n",
    "np.save('model_data/val_labels_enc.npy', val_labels_enc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 0.6 Loading saved Tensors (can avoid 1.1-1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_imgs_scaled = np.load('model_data/val_imgs_scaled.npy')\n",
    "train_imgs_scaled = np.load('model_data/train_imgs_scaled.npy')\n",
    "val_labels_enc = np.load('model_data/val_labels_enc.npy')\n",
    "train_labels_enc = np.load('model_data/train_labels_enc.npy')\n",
    "\n",
    "print(val_imgs_scaled.shape)\n",
    "print(train_imgs_scaled.shape)\n",
    "print(val_labels_enc.shape)\n",
    "print(train_labels_enc.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Traditional CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 CNN Model 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu', \n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(32, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(42, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=RMSprop(),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_1_1_noaug_epoch_\" in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_1_1_noaug_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_1_1_noaug_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(train_imgs_scaled, train_labels_enc,\n",
    "                   validation_data=(val_imgs_scaled, val_labels_enc),\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1)\n",
    "\n",
    "model_1_1_noaug_epoch_count += 1\n",
    "save_model(model, 'model_data/model_1_1_noaug_epoch_{}.h5'.format(model_1_1_noaug_epoch_count))\n",
    "print('Total Epoch Count: ', model_1_1_noaug_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 CNN Model 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(Conv2D(16, kernel_size=(3, 3), activation='relu', \n",
    "                 input_shape=input_shape))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(64, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Conv2D(128, kernel_size=(3, 3), activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(42, activation='sigmoid'))\n",
    "\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.RMSprop(lr=2e-5),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_1_2_noaug_epoch_\" in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_1_2_noaug_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_1_2_noaug_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(train_imgs_scaled, train_labels_enc,\n",
    "                   validation_data=(val_imgs_scaled, val_labels_enc),\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1)\n",
    "\n",
    "model_1_2_noaug_epoch_count += 1\n",
    "save_model(model, 'model_data/model_1_2_noaug_epoch_{}.h5'.format(model_1_2_noaug_epoch_count))\n",
    "print('Total Epoch Count: ', model_1_2_noaug_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Transfer-Learning Feature Extraction: VGG16"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Without Augmentation, Without FineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this once\n",
    "\n",
    "from keras.applications import vgg16\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n",
    "                                     input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = Flatten() (output)\n",
    "output = Dense(512, activation='relu') (output)\n",
    "output = Dropout(0.3) (output)\n",
    "output = Dense(512, activation='relu') (output)\n",
    "output = Dropout(0.3) (output)\n",
    "output = Dense(42, activation='sigmoid') (output)\n",
    "\n",
    "model = Model(vgg.input, output)\n",
    "\n",
    "model.trainable = True\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    for layer in vgg.layers:\n",
    "        if layer.name in ['block5_conv1', 'block4_conv1']:\n",
    "            layer.trainable = True\n",
    "\n",
    "            \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "print(model.summary())\n",
    "pd.set_option('max_colwidth', -1)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_2_noaug_nofinetune_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_2_noaug_nofinetune_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_2_noaug_nofinetune_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(train_imgs_scaled, train_labels_enc,\n",
    "                   validation_data=(val_imgs_scaled, val_labels_enc),\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1)\n",
    "\n",
    "model_2_noaug_nofinetune_epoch_count += 1\n",
    "save_model(model, 'model_data/model_2_noaug_nofinetune_epoch_{}.h5'.format(model_2_noaug_nofinetune_epoch_count))\n",
    "print('Total Epoch Count: ', model_2_noaug_nofinetune_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3 Without Augmentation, With Fine-Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this once\n",
    "\n",
    "from keras.applications import vgg16\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n",
    "                                     input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "output = Flatten() (output)\n",
    "output = Dense(512, activation='relu') (output)\n",
    "output = Dropout(0.3) (output)\n",
    "output = Dense(512, activation='relu') (output)\n",
    "output = Dropout(0.3) (output)\n",
    "output = Dense(42, activation='sigmoid') (output)\n",
    "\n",
    "model = Model(vgg.input, output)\n",
    "\n",
    "model.trainable = True\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = False\n",
    "    \n",
    "fine_tuning = True\n",
    "if fine_tuning:\n",
    "    for layer in vgg.layers:\n",
    "        if layer.name in ['block5_conv1', 'block4_conv1']:\n",
    "            layer.trainable = True\n",
    "\n",
    "            \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "print(model.summary())\n",
    "pd.set_option('max_colwidth', -1)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_2_noaug_yesfinetune_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_2_noaug_yesfinetune_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_2_noaug_yesfinetune_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(train_imgs_scaled, train_labels_enc,\n",
    "                   validation_data=(val_imgs_scaled, val_labels_enc),\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1)\n",
    "\n",
    "model_2_noaug_yesfinetune_epoch_count += 1\n",
    "save_model(model, 'model_data/model_2_noaug_yesfinetune_epoch_{}.h5'.format(model_2_noaug_yesfinetune_epoch_count))\n",
    "print('Total Epoch Count: ', model_2_noaug_yesfinetune_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.5 With Augmentation, With Revamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only run this once\n",
    "\n",
    "from keras.applications import vgg16\n",
    "\n",
    "vgg = vgg16.VGG16(include_top=False, weights='imagenet', \n",
    "                                     input_shape=input_shape)\n",
    "\n",
    "output = vgg.layers[-1].output\n",
    "# output = Flatten() (output)\n",
    "output = GlobalAveragePooling2D() (output)\n",
    "output = Dense(512, activation='relu') (output)\n",
    "output = Dense(42, activation='sigmoid') (output)\n",
    "\n",
    "model = Model(vgg.input, output)\n",
    "\n",
    "model.trainable = True\n",
    "for layer in vgg.layers:\n",
    "    layer.trainable = True\n",
    "    \n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    for layer in vgg.layers:\n",
    "        if layer.name in ['block5_conv1', 'block4_conv1']:\n",
    "            layer.trainable = True\n",
    "\n",
    "            \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "print(model.summary())\n",
    "pd.set_option('max_colwidth', -1)\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_2_yesaug_yesrevamp_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_2_yesaug_yesrevamp_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_2_yesaug_yesrevamp_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 100\n",
    "EPOCHS = 1\n",
    "\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip ='true')\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs_scaled, \n",
    "                                     train_labels_enc, \n",
    "                                     shuffle=True, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     seed=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "val_generator = train_datagen.flow(val_imgs_scaled, \n",
    "                                   val_labels_enc, \n",
    "                                   shuffle=False, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   seed=1)   \n",
    "\n",
    "train_steps_per_epoch = train_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = val_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)\n",
    "\n",
    "history = model.fit(train_imgs_scaled, train_labels_enc,\n",
    "                   validation_data=(val_imgs_scaled, val_labels_enc),\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1)\n",
    "\n",
    "model_2_yesaug_yesrevamp_epoch_count += 1\n",
    "save_model(model, 'model_data/model_2_yesaug_yesrevamp_epoch_{}.h5'.format(model_2_yesaug_yesrevamp_epoch_count))\n",
    "print('Total Epoch Count: ', model_2_yesaug_yesrevamp_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Google's Inception V3 Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Without Augmentation, Without Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_inception = InceptionV3(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = True\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_3_noaug_nofinetune_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_3_noaug_nofinetune_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_3_noaug_nofinetune_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(train_imgs_scaled, train_labels_enc,\n",
    "                   validation_data=(val_imgs_scaled, val_labels_enc),\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1)\n",
    "\n",
    "model_3_noaug_nofinetune_epoch_count += 1\n",
    "save_model(model, 'model_data/model_3_noaug_nofinetune_epoch_{}.h5'.format(model_3_noaug_nofinetune_epoch_count))\n",
    "print('Total Epoch Count: ', model_3_noaug_nofinetune_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.1.2 Testing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "model_name = 'model_3_noaug_nofinetune_epoch_{}.h5'.format(version)\n",
    "test = load_model('model_data/' + model_name)\n",
    "result = test.predict(val_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(10) / 10:\n",
    "    count = 0\n",
    "    denom = 0\n",
    "    for i in range(len(val_imgs_scaled)):\n",
    "        if result[i].max() > j:\n",
    "            denom += 1\n",
    "            if np.argmax(result[i]) == np.argmax(val_labels_enc[i]):\n",
    "                count += 1\n",
    "    print(j, round(denom/len(val_imgs_scaled), 3), round(count/denom, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 With Augmentation, Without FineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_inception = InceptionV3(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = True\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_3_yesaug_nofinetune_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_3_yesaug_nofinetune_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_3_yesaug_nofinetune_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip ='true')\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs_scaled, \n",
    "                                     train_labels_enc, \n",
    "                                     shuffle=True, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     seed=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "val_generator = train_datagen.flow(val_imgs_scaled, \n",
    "                                   val_labels_enc, \n",
    "                                   shuffle=False, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   seed=1)   \n",
    "\n",
    "\n",
    "train_steps_per_epoch = train_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = val_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)\n",
    "\n",
    "model_3_yesaug_nofinetune_epoch_count += 1\n",
    "save_model(model, 'model_data/model_3_yesaug_nofinetune_epoch_{}.h5'.format(model_3_yesaug_nofinetune_epoch_count))\n",
    "print('Total Epoch Count: ', model_3_yesaug_nofinetune_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Without Augmentation, With Fine Tuning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_inception = InceptionV3(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = True\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_3_noaug_yesfinetune_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_3_noaug_yesfinetune_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_3_noaug_yesfinetune_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "history = model.fit(train_imgs_scaled, train_labels_enc,\n",
    "                   validation_data=(val_imgs_scaled, val_labels_enc),\n",
    "                   batch_size=BATCH_SIZE,\n",
    "                   epochs=EPOCHS,\n",
    "                   verbose=1)\n",
    "\n",
    "noaug_yesfinetune_epoch_count += 1\n",
    "save_model(model, 'model_data/model_3_noaug_yesfinetune_epoch_{}.h5'.format(noaug_yesfinetune_epoch_count))\n",
    "print('Total Epoch Count: ', noaug_yesfinetune_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.3.2 Testing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 1\n",
    "model_name = 'model_3_noaug_yesfinetune_epoch_{}.h5'.format(version)\n",
    "test = load_model('model_data/' + model_name)\n",
    "result = test.predict(val_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for j in np.arange(10) / 10:\n",
    "    count = 0\n",
    "    denom = 0\n",
    "    for i in range(len(val_imgs_scaled)):\n",
    "        if result[i].max() > j:\n",
    "            denom += 1\n",
    "            if np.argmax(result[i]) == np.argmax(val_labels_enc[i]):\n",
    "                count += 1\n",
    "    print(j, round(denom/len(val_imgs_scaled), 3), round(count/denom, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 With Augmentation, With FineTune"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ONLY RUN THIS CELL ONCE\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_inception = InceptionV3(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = True\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = True\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_3_yesaug_yesfinetune_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_3_yesaug_yesfinetune_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_3_yesaug_yesfinetune_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip ='true')\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs_scaled, \n",
    "                                     train_labels_enc, \n",
    "                                     shuffle=True, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     seed=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "val_generator = train_datagen.flow(val_imgs_scaled, \n",
    "                                   val_labels_enc, \n",
    "                                   shuffle=False, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   seed=1)   \n",
    "\n",
    "\n",
    "train_steps_per_epoch = train_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = val_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)\n",
    "\n",
    "model_3_yesaug_yesfinetune_epoch_count += 1\n",
    "save_model(model, 'model_data/model_3_yesaug_yesfinetune_epoch_{}.h5'.format(model_3_yesaug_yesfinetune_epoch_count))\n",
    "print('Total Epoch Count: ', model_3_yesaug_yesfinetune_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.4.2 Testing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 2\n",
    "model_name = 'model_3_yesaug_yesfinetune_epoch_{}.h5'.format(version)\n",
    "test = load_model('model_data/' + model_name)\n",
    "result = test.predict(val_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in np.arange(10) / 10:\n",
    "    count = 0\n",
    "    denom = 0\n",
    "    for i in range(len(val_imgs_scaled)):\n",
    "        if result[i].max() > j:\n",
    "            denom += 1\n",
    "            if np.argmax(result[i]) == np.argmax(val_labels_enc[i]):\n",
    "                count += 1\n",
    "    print(j, round(denom/len(val_imgs_scaled), 3), round(count/denom, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 With Augmentation, With Revamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ONLY RUN THIS CELL ONCE\n",
    "\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_inception = InceptionV3(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = False\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.options.display.max_rows = None\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_3_yesaug_yesrevamp_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_3_yesaug_yesrevamp_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_3_yesaug_yesrevamp_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip ='true')\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs_scaled, \n",
    "                                     train_labels_enc, \n",
    "                                     shuffle=True, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     seed=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "val_generator = train_datagen.flow(val_imgs_scaled, \n",
    "                                   val_labels_enc, \n",
    "                                   shuffle=False, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   seed=1)   \n",
    "\n",
    "\n",
    "train_steps_per_epoch = train_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = val_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)+\n",
    "\n",
    "\n",
    "model_3_yesaug_yesrevamp_epoch_count += 1\n",
    "save_model(model, 'model_data/model_3_yesaug_yesrevamp_epoch_{}.h5'.format(model_3_yesaug_yesrevamp_epoch_count))\n",
    "print('Total Epoch Count: ', model_3_yesaug_yesrevamp_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.5.2 Testing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 2\n",
    "model_name = 'model_3_yesaug_yesrevamp_epoch_{}.h5'.format(version)\n",
    "test = load_model('model_data/' + model_name)\n",
    "result = test.predict(val_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(result, axis=1)\n",
    "act = np.argmax(val_labels_enc, axis=1)\n",
    "\n",
    "act_total_count = [0] * 42\n",
    "correct_total_count = [0] * 42\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if max(result[i] > 0):\n",
    "        act_total_count[act[i]] += 1\n",
    "        if pred[i] == act[i]:\n",
    "            correct_total_count[act[i]] += 1\n",
    "\n",
    "print('Count: ', sum(act_total_count), '({}%)'.format(round(sum(act_total_count)*100/len(pred), 2)))\n",
    "print('Overall Accuracy: ', round(sum(correct_total_count) / sum(act_total_count), 2))\n",
    "print()\n",
    "print('cat\\t', 'accuracy')\n",
    "for cat, prob in sorted(enumerate(list(map(lambda x: x[0]/x[1], list(zip(correct_total_count, act_total_count))))), key=lambda x:-x[1]):\n",
    "    print(cat, '\\t', round(prob, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in np.arange(10) / 10:\n",
    "    count = 0\n",
    "    denom = 0\n",
    "    for i in range(len(val_imgs_scaled)):\n",
    "        if result[i].max() > j:\n",
    "            denom += 1\n",
    "            if np.argmax(result[i]) == np.argmax(val_labels_enc[i]):\n",
    "                count += 1\n",
    "    print(j, round(denom/len(val_imgs_scaled), 3), round(count/denom, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.6 With Augmentation & Revamp BUT Different FullyConectedLayer & SGD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ONLY RUN THIS CELL ONCE\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "base_inception = InceptionV3(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(1024, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = False\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(SGD(lr=0.0001, momentum=0.9), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.options.display.max_rows = None\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_3_yesaug_yesrevamp_params2_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_3_yesaug_yesrevamp_params2_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_3_yesaug_yesrevamp_params2_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip ='true')\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs_scaled, \n",
    "                                     train_labels_enc, \n",
    "                                     shuffle=True, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     seed=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "val_generator = train_datagen.flow(val_imgs_scaled, \n",
    "                                   val_labels_enc, \n",
    "                                   shuffle=False, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   seed=1)   \n",
    "\n",
    "\n",
    "train_steps_per_epoch = train_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = val_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)\n",
    "\n",
    "\n",
    "model_3_yesaug_yesrevamp_params2_epoch_count += 1\n",
    "save_model(model, 'model_data/model_3_yesaug_yesrevamp_params2_epoch_{}.h5'.format(model_3_yesaug_yesrevamp_params2_epoch_count))\n",
    "print('Total Epoch Count: ', model_3_yesaug_yesrevamp_params2_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3.6.2 Testing Trained Models"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "| epoch | accuracy |\n",
    "| --- | --- |\n",
    "| 1 | |\n",
    "| 2 | |"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 2\n",
    "model_name = 'model_3_yesaug_yesrevamp_params2_epoch_{}.h5'.format(version)\n",
    "test = load_model('model_data/' + model_name)\n",
    "result = test.predict(val_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = np.argmax(result, axis=1)\n",
    "act = np.argmax(val_labels_enc, axis=1)\n",
    "\n",
    "act_total_count = [0] * 42\n",
    "correct_total_count = [0] * 42\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if max(result[i] > 0):\n",
    "        act_total_count[act[i]] += 1\n",
    "        if pred[i] == act[i]:\n",
    "            correct_total_count[act[i]] += 1\n",
    "\n",
    "print('Count: ', sum(act_total_count), '({}%)'.format(round(sum(act_total_count)*100/len(pred), 2)))\n",
    "print('Overall Accuracy: ', round(sum(correct_total_count) / sum(act_total_count), 2))\n",
    "print()\n",
    "print('cat\\t', 'accuracy')\n",
    "for cat, prob in sorted(enumerate(list(map(lambda x: x[0]/x[1], list(zip(correct_total_count, act_total_count))))), key=lambda x:-x[1]):\n",
    "    print(cat, '\\t', round(prob, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for j in np.arange(10) / 10:\n",
    "    count = 0\n",
    "    denom = 0\n",
    "    for i in range(len(val_imgs_scaled)):\n",
    "        if result[i].max() > j:\n",
    "            denom += 1\n",
    "            if np.argmax(result[i]) == np.argmax(val_labels_enc[i]):\n",
    "                count += 1\n",
    "    print(j, round(denom/len(val_imgs_scaled), 3), round(count/denom, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. mobilenet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 With Augmentation, With Revamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ONLY RUN THIS CELL ONCE\n",
    "\n",
    "from keras.applications import MobileNet\n",
    "\n",
    "base_inception = MobileNet(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = False\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.options.display.max_rows = None\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_4_yesaug_yesrevamp_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_4_yesaug_yesrevamp_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_4_yesaug_yesrevamp_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip ='true')\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs_scaled, \n",
    "                                     train_labels_enc, \n",
    "                                     shuffle=True, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     seed=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "val_generator = train_datagen.flow(val_imgs_scaled, \n",
    "                                   val_labels_enc, \n",
    "                                   shuffle=False, \n",
    "                                   batch_size=1, \n",
    "                                   seed=1)   \n",
    "\n",
    "\n",
    "train_steps_per_epoch = train_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = val_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)\n",
    "\n",
    "\n",
    "model_4_yesaug_yesrevamp_epoch_count += 1\n",
    "save_model(model, 'model_data/model_4_yesaug_yesrevamp_epoch_{}.h5'.format(model_4_yesaug_yesrevamp_epoch_count))\n",
    "print('Total Epoch Count: ', model_4_yesaug_yesrevamp_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1.2 Testing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 3\n",
    "model_name = 'model_4_yesaug_yesrevamp_epoch_{}.h5'.format(version)\n",
    "model = load_model('model_data/' + model_name)\n",
    "result = model.predict(val_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRES = 0\n",
    "\n",
    "pred = np.argmax(result, axis=1)\n",
    "act = np.argmax(val_labels_enc, axis=1)\n",
    "\n",
    "act_total_count = [0] * 42\n",
    "correct_total_count = [0] * 42\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if max(result[i] > THRES):\n",
    "        act_total_count[act[i]] += 1\n",
    "        if pred[i] == act[i]:\n",
    "            correct_total_count[act[i]] += 1\n",
    "\n",
    "print('Count: ', sum(act_total_count), '({}%)'.format(round(sum(act_total_count)*100/len(pred), 3)))\n",
    "print('Overall Accuracy: ', round(sum(correct_total_count) / sum(act_total_count), 3))\n",
    "print()\n",
    "print('cat\\t', 'accuracy')\n",
    "for cat, prob in sorted(enumerate(list(map(lambda x: x[0]/x[1], list(zip(correct_total_count, act_total_count))))), key=lambda x:-x[1]):\n",
    "    print(cat, '\\t', round(prob, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j in np.arange(10) / 10:\n",
    "    count = 0\n",
    "    denom = 0\n",
    "    for i in range(len(val_imgs_scaled)):\n",
    "        if result[i].max() > j:\n",
    "            denom += 1\n",
    "            if np.argmax(result[i]) == np.argmax(val_labels_enc[i]):\n",
    "                count += 1\n",
    "    print(j, round(denom/len(val_imgs_scaled), 3), round(count/denom, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. RESNET50"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5.1 With Augmentation, With Revamp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_shape = (IMG_DIM[0], IMG_DIM[1], 3)\n",
    "print(input_shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "### ONLY RUN THIS CELL ONCE\n",
    "\n",
    "from keras.applications import ResNet50\n",
    "\n",
    "base_inception = ResNet50(weights='imagenet', include_top=False, \n",
    "                             input_shape=input_shape)\n",
    "                             \n",
    "out = base_inception.output\n",
    "out = GlobalAveragePooling2D()(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "out = Dense(512, activation='relu')(out)\n",
    "predictions = Dense(42, activation='softmax')(out)\n",
    "\n",
    "model = Model(inputs=base_inception.input, \n",
    "              outputs=predictions)\n",
    "\n",
    "freeze_base = False\n",
    "if freeze_base:\n",
    "    for layer in base_inception.layers:\n",
    "        layer.trainable = False\n",
    "\n",
    "fine_tuning = False\n",
    "if fine_tuning:\n",
    "    unfreeze_list = [x.name for x in model.layers if 'batch_normalization' in x.name][-2:]\n",
    "    unfreeze_list.append([x.name for x in model.layers if 'conv2d' in x.name][-1])\n",
    "    for layer in base_inception.layers:\n",
    "        if layer.name in unfreeze_list:\n",
    "            layer.trainable = True\n",
    "        \n",
    "model.compile(Adam(lr=.0001), \n",
    "              loss='categorical_crossentropy', \n",
    "              metrics=['accuracy']) \n",
    "\n",
    "model.summary()\n",
    "pd.options.display.max_colwidth = None\n",
    "pd.options.display.max_rows = None\n",
    "layers = [(layer, layer.name, layer.trainable) for layer in model.layers]\n",
    "pd.DataFrame(layers, columns=['Layer Type', 'Layer Name', 'Layer Trainable'])    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mod_list = [mod for mod in os.listdir('model_data') if \"model_5_yesaug_yesrevamp_epoch_\"in mod]\n",
    "if len(mod_list) == 0:\n",
    "    model_5_yesaug_yesrevamp_epoch_count = 0\n",
    "else:\n",
    "    model_name = max(mod_list)\n",
    "    model = load_model('model_data/' + model_name)\n",
    "    model_5_yesaug_yesrevamp_epoch_count = int(max(mod_list).split('epoch_')[1][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 32\n",
    "EPOCHS = 1\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale=1, \n",
    "                                   rotation_range=20, \n",
    "                                   width_shift_range=0.1,\n",
    "                                   height_shift_range=0.1, \n",
    "                                   horizontal_flip ='true')\n",
    "\n",
    "train_generator = train_datagen.flow(train_imgs_scaled, \n",
    "                                     train_labels_enc, \n",
    "                                     shuffle=True, \n",
    "                                     batch_size=BATCH_SIZE, \n",
    "                                     seed=1)\n",
    "\n",
    "val_datagen = ImageDataGenerator(rescale = 1)\n",
    "\n",
    "val_generator = train_datagen.flow(val_imgs_scaled, \n",
    "                                   val_labels_enc, \n",
    "                                   shuffle=False, \n",
    "                                   batch_size=BATCH_SIZE, \n",
    "                                   seed=1)   \n",
    "\n",
    "\n",
    "train_steps_per_epoch = train_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "val_steps_per_epoch = val_imgs_scaled.shape[0] // BATCH_SIZE\n",
    "\n",
    "\n",
    "history = model.fit_generator(train_generator,\n",
    "                              steps_per_epoch=train_steps_per_epoch,\n",
    "                              validation_data=val_generator,\n",
    "                              validation_steps=val_steps_per_epoch,\n",
    "                              epochs=EPOCHS, \n",
    "                              verbose=1)\n",
    "\n",
    "\n",
    "model_5_yesaug_yesrevamp_epoch_count += 1\n",
    "save_model(model, 'model_data/model_5_yesaug_yesrevamp_epoch_{}.h5'.format(model_5_yesaug_yesrevamp_epoch_count))\n",
    "print('Total Epoch Count: ', model_5_yesaug_yesrevamp_epoch_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 5.1.2 Testing Trained Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 2\n",
    "model_name = 'model_5_yesaug_yesrevamp_epoch_{}.h5'.format(version)\n",
    "model = load_model('model_data/' + model_name)\n",
    "result = model.predict(val_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "THRES = 0\n",
    "\n",
    "pred = np.argmax(result, axis=1)\n",
    "act = np.argmax(val_labels_enc, axis=1)\n",
    "\n",
    "act_total_count = [0] * 42\n",
    "correct_total_count = [0] * 42\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    if max(result[i] > THRES):\n",
    "        act_total_count[act[i]] += 1\n",
    "        if pred[i] == act[i]:\n",
    "            correct_total_count[act[i]] += 1\n",
    "\n",
    "print('Count: ', sum(act_total_count), '({}%)'.format(round(sum(act_total_count)*100/len(pred), 2)))\n",
    "print('Overall Accuracy: ', round(sum(correct_total_count) / sum(act_total_count), 3))\n",
    "print()\n",
    "print('cat\\t', 'accuracy')\n",
    "for cat, prob in sorted(enumerate(list(map(lambda x: x[0]/x[1], list(zip(correct_total_count, act_total_count))))), key=lambda x:-x[1]):\n",
    "    print(cat, '\\t', round(prob, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for j in np.arange(10) / 10:\n",
    "    count = 0\n",
    "    denom = 0\n",
    "    for i in range(len(val_imgs_scaled)):\n",
    "        if result[i].max() > j:\n",
    "            denom += 1\n",
    "            if np.argmax(result[i]) == np.argmax(val_labels_enc[i]):\n",
    "                count += 1\n",
    "    print(j, round(denom/len(val_imgs_scaled), 3), round(count/denom, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. FINAL SET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_DIM = (150, 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = list()\n",
    "bad_test_imgs = list()\n",
    "\n",
    "ii = 0\n",
    "all_paths = os.listdir('data/test/test/')\n",
    "finish = len(all_path)\n",
    "\n",
    "for img in all_paths:\n",
    "    \n",
    "    path = 'data/test/test/' + img\n",
    "    \n",
    "    try:\n",
    "        test_imgs.append(img_to_array(load_img(\n",
    "                path, target_size=IMG_DIM)))       \n",
    "\n",
    "    except:\n",
    "\n",
    "        bad_test_imgs.append(path)\n",
    "\n",
    "    ii += 1\n",
    "    update_progress(ii/finish)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs = np.array(test_imgs)\n",
    "test_imgs_scaled = test_imgs.astype('float32')\n",
    "test_imgs_scaled /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_imgs_scaled.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('model_data/test_imgs_scaled.npy', test_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_imgs_scaled = np.load('model_data/test_imgs_scaled.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "version = 2\n",
    "model_name = 'model_3_yesaug_yesrevamp_epoch_{}.h5'.format(version)\n",
    "model = load_model('model_data/' + model_name)\n",
    "test_result = model.predict(test_imgs_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_to_img = dict()\n",
    "for i in range(42):\n",
    "    label_to_img[i] = list()\n",
    "    \n",
    "pred = np.argmax(test_result, axis=1)\n",
    "\n",
    "for i in range(len(pred)):\n",
    "    label_to_img[pred[i]].append(i)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for cat in range(42):\n",
    "    print(\"###########     CATEGORY {}       #############\".format(cat))\n",
    "    fig, ax = plt.subplots(10,10, figsize=(20,20))\n",
    "    ax = ax.ravel()\n",
    "\n",
    "    jj = 0\n",
    "    for ind in label_to_img[cat][:100]:\n",
    "        ax[jj].imshow(array_to_img(test_imgs_scaled[ind]))\n",
    "        ax[jj].axis('off')\n",
    "        jj += 1\n",
    "    plt.savefig('test_results/cat_{}.png'.format(cat))\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Anaconda Python",
   "language": "python",
   "name": "base"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
